{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def global1():\n",
    "    global munimap\n",
    "    munimap = {'pitcairn':847}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accessGlobal():\n",
    "    print(munimap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "accessGlobal()\n",
    "\n",
    "def get_nextpropertyid():\n",
    "    # consider a range multiplier by municipality to generate starting \n",
    "    # at, say 110000 and the next at 120000 which allows for non-overlapping\n",
    "    #ids for munis with a property count of up to 10000\n",
    "    for i in list(range(100000, 110000)):\n",
    "        yield int(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "100001\n",
      "100002\n"
     ]
    }
   ],
   "source": [
    "proplist = [121,122,123]\n",
    "gen = get_nextpropertyid()\n",
    "for s in proplist:\n",
    "    print(next(gen))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471&nbsp;WALNUT  ST\n",
      "471 WALNUT ST\n",
      "PITTSBURGH,&nbsp;PA&nbsp;15238\n",
      "PITTSBURGH\n",
      "15238\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import bs4\n",
    "\n",
    "testtext = '471&nbsp;WALNUT  ST<br>PITTSBURGH,&nbsp;PA&nbsp;15238'\n",
    "splitlinelist = testtext.split('>')\n",
    "\n",
    "exp = re.compile(r'\\d*[^<]*')\n",
    "adr = exp.search(splitlinelist[0])\n",
    "print(adr.group(0))\n",
    "street = re.sub(r'&nbsp;', ' ', adr.group())\n",
    "street = re.sub('  ', ' ', street)\n",
    "print(street)\n",
    "print(splitlinelist[1])\n",
    "exp = re.compile('[^,]*')\n",
    "city = exp.search(splitlinelist[1])\n",
    "print(city.group(0))\n",
    "# exp=re.compile('[\\d]$+')\n",
    "# zip = exp.search(splitlinelist[1])\n",
    "print(splitlinelist[1][-5:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    INSERT INTO codeenfevent\n",
      "            (eventID, eventDate, eventDescription, letterText,\n",
      "            codeOfficer_officerID, codeEnfCase_caseID, EventTyp_codeEnfEventTypeID)\n",
      "        VALUES (sdf, jan1, very important)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "valuemap = {'eventID':'sdf', 'eventDate':'jan1','eventDescription':'very important'}\n",
    "sql = \"\"\"\n",
    "    INSERT INTO codeenfevent\n",
    "            (eventID, eventDate, eventDescription, letterText,\n",
    "            codeOfficer_officerID, codeEnfCase_caseID, EventTyp_codeEnfEventTypeID)\n",
    "        VALUES (%(eventID)s, %(eventDate)s, %(eventDescription)s)\n",
    "\"\"\"\n",
    "\n",
    "print(sql%valuemap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the the\n",
      "the\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "no such group",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-142-1bb46ac63d7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: no such group"
     ]
    }
   ],
   "source": [
    "p = re.compile(r'\\b(\\w+)\\s+\\1\\b')\n",
    "g = p.search('Paris in the the spring')\n",
    "print(g.group())\n",
    "print(g.group(1))\n",
    "print(g.group(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<span class=\"Data\" id=\"BasicInfo1_lblAddress\">618 AIRBRAKE  AVE<br/>WILMERDING, PA 15148</span>']\n",
      "street:1_lblAddress\">618 AIRBRAKE  AVE\n",
      "city:WILMERDING\n",
      "Zip: 15148\n"
     ]
    }
   ],
   "source": [
    "### Tinkering with using regular expression splitting to parse out the address components for owners scraped\n",
    "### from county browser-based front end\n",
    "scrapedhtml = r'''<span class=\"Data\" id=\"BasicInfo1_lblAddress\">618 AIRBRAKE  AVE<br/>WILMERDING, PA 15148</span>'''\n",
    "l = re.split('<\\w>', scrapedhtml) \n",
    "print(l)\n",
    "\n",
    "splitlinelist = str(scrapedhtml).split('>')\n",
    "propaddrmap = {}\n",
    "if(len(splitlinelist) >= 2):\n",
    "    # match beg until any character not a <\n",
    "    exp = re.compile(r'\\d+[^<]*')\n",
    "    adr = exp.search(str(scrapedhtml))\n",
    "    # replace the html escape space with a single space\n",
    "    street = re.sub('&nbsp;', ' ', adr.group())\n",
    "    print(\"street:\" + street)\n",
    "    # take pairs of spaces down to one space\n",
    "    propaddrmap['street'] = re.sub('  ', ' ', street)\n",
    "    # on the city, state, zip line, grab until the comma before the state\n",
    "    exp = re.compile('[^,]*')\n",
    "    propaddrmap['city'] = exp.search(splitlinelist[2]).group()\n",
    "    print(\"city:\" + propaddrmap['city'])\n",
    "    # hard-code pa\n",
    "    propaddrmap['state']= 'PA'\n",
    "    # zip is just the last 5 chars    \n",
    "    propaddrmap['zip'] = splitlinelist[2][-12:-6]\n",
    "    print(\"Zip:\" + propaddrmap['zip'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: \n",
      "Important Text 1\n",
      "\n",
      "Found: \n",
      "Not Important Text\n",
      "\n",
      "Found: \n",
      "Important Text 2\n",
      "\n",
      "Found: \n",
      "Important Text 3\n",
      "\n",
      "Found: \n",
      "Non Important Text\n",
      "\n",
      "Found: \n",
      "Important Text 4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sylvia/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /home/sylvia/anaconda3/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "### Grabbed from SO on parsing out strangely structured HTML with BeatutifulSoup\n",
    "\n",
    "from bs4 import BeautifulSoup, NavigableString, Tag\n",
    "\n",
    "input = '''<br />\n",
    "Important Text 1\n",
    "<br />\n",
    "<br />\n",
    "Not Important Text\n",
    "<br />\n",
    "Important Text 2\n",
    "<br />\n",
    "Important Text 3\n",
    "<br />\n",
    "<br />\n",
    "Non Important Text\n",
    "<br />\n",
    "Important Text 4\n",
    "<br />'''\n",
    "\n",
    "soup = BeautifulSoup(input)\n",
    "\n",
    "for br in soup.findAll('br'):\n",
    "    next_s = br.nextSibling\n",
    "    if not (next_s and isinstance(next_s,NavigableString)):\n",
    "        continue\n",
    "    next2_s = next_s.nextSibling\n",
    "    if next2_s and isinstance(next2_s,Tag) and next2_s.name == 'br':\n",
    "        text = str(next_s).strip()\n",
    "        if text:\n",
    "            print(\"Found:\", next_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['618 AIRBRAKE  AVE', <br/>, 'WILMERDING,     PA 15148-23423']\n",
      "48\n",
      "PA\n",
      "15148\n",
      "<br/>\n",
      "done sleeping\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "scrapedhtml = r'''<span class=\"Data\" id=\"BasicInfo1_lblAddress\">618 AIRBRAKE  AVE<br/>WILMERDING,     PA 15148-23423</span>'''\n",
    "# scrapedhtml = r'''<span class=\"Data\" id=\"BasicInfo1_lblAddress\"><br/>WILMERDING, PA 15148</span>'''\n",
    "soup = BeautifulSoup(scrapedhtml, 'lxml')\n",
    "magiclist = soup.span.contents\n",
    "print(soup.span.contents)\n",
    "print(magiclist[2][-8:-6])\n",
    "exp=re.compile(',\\s*(\\w\\w)')\n",
    "m = re.search(exp,magiclist[2])\n",
    "print(m.group(1))\n",
    "exp=re.compile('\\d+')\n",
    "m = re.search(exp, magiclist[2])\n",
    "print(m.group())\n",
    "print(soup.span.br)\n",
    "time.sleep(3.232)\n",
    "print(\"done sleeping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "('BOBERG', '&', 'JOHN')\n",
      "& John Boberg\n"
     ]
    }
   ],
   "source": [
    "owner_full_name = r'''BOBERG & JOHN A &  LORRAINE A (W)    '''\n",
    "persondict = {}\n",
    "# soup = bs4.BeautifulSoup(property_html, 'lxml')\n",
    "# owner_full_name = soup.find('span', id=OWNER_NAME_SPAN_ID).text\n",
    "# Remove extra spaces from owner's name\n",
    "# persondict['note_namedump'] = re.sub(r'\\s+', ' ', owner_full_name.strip())\n",
    "exp = re.compile(r'(\\w+|[&])\\s+(\\w+|[&])\\s+(\\w+|[&]).*')\n",
    "namegroups = re.search(exp,owner_full_name)\n",
    "print(len(namegroups.groups()))\n",
    "print(namegroups.groups())\n",
    "persondict['lname'] = namegroups.group(1)\n",
    "persondict['fname'] = str(namegroups.group(2)) + ' ' + str(namegroups.group(3))\n",
    "print(str(persondict['fname']).title() + ' ' + str(persondict['lname']).title())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "# basic testing of error file writing\n",
    "output_file = 'errorparcels.csv'\n",
    "CSV_FILE_ENCODING = 'utf-8'\n",
    "\n",
    "def logerror(parcelid):\n",
    "    fieldnames = None\n",
    "    with open(output_file, 'a', encoding=CSV_FILE_ENCODING) as outfile:\n",
    "        writer = csv.writer(outfile)\n",
    "        writer.writerow(parcelid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'_csv.writer' object has no attribute 'write'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-241-8f3d805d11c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlogerror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sdf2342'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-240-980935756f30>\u001b[0m in \u001b[0;36mlogerror\u001b[0;34m(parcelid)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCSV_FILE_ENCODING\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moutfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparcelid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: '_csv.writer' object has no attribute 'write'"
     ]
    }
   ],
   "source": [
    "logerror('sdf2342')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
