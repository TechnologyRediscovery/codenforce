{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def global1():\n",
    "    global munimap\n",
    "    munimap = {'pitcairn':847}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accessGlobal():\n",
    "    print(munimap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accessGlobal()\n",
    "\n",
    "def get_nextpropertyid():\n",
    "    # consider a range multiplier by municipality to generate starting \n",
    "    # at, say 110000 and the next at 120000 which allows for non-overlapping\n",
    "    #ids for munis with a property count of up to 10000\n",
    "    for i in list(range(100000, 110000)):\n",
    "        yield int(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "proplist = [121,122,123]\n",
    "gen = get_nextpropertyid()\n",
    "for s in proplist:\n",
    "    print(next(gen))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471&nbsp;WALNUT  ST\n",
      "471 WALNUT ST\n",
      "PITTSBURGH,&nbsp;PA&nbsp;15238\n",
      "PITTSBURGH\n",
      "15238\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import bs4\n",
    "\n",
    "testtext = '471&nbsp;WALNUT  ST<br>PITTSBURGH,&nbsp;PA&nbsp;15238'\n",
    "splitlinelist = testtext.split('>')\n",
    "\n",
    "exp = re.compile(r'\\d*[^<]*')\n",
    "adr = exp.search(splitlinelist[0])\n",
    "print(adr.group(0))\n",
    "street = re.sub(r'&nbsp;', ' ', adr.group())\n",
    "street = re.sub('  ', ' ', street)\n",
    "print(street)\n",
    "print(splitlinelist[1])\n",
    "exp = re.compile('[^,]*')\n",
    "city = exp.search(splitlinelist[1])\n",
    "print(city.group(0))\n",
    "# exp=re.compile('[\\d]$+')\n",
    "# zip = exp.search(splitlinelist[1])\n",
    "print(splitlinelist[1][-5:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valuemap = {'eventID':'sdf', 'eventDate':'jan1','eventDescription':'very important'}\n",
    "sql = \"\"\"\n",
    "    INSERT INTO codeenfevent\n",
    "            (eventID, eventDate, eventDescription, letterText,\n",
    "            codeOfficer_officerID, codeEnfCase_caseID, EventTyp_codeEnfEventTypeID)\n",
    "        VALUES (%(eventID)s, %(eventDate)s, %(eventDescription)s)\n",
    "\"\"\"\n",
    "\n",
    "print(sql%valuemap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = re.compile(r'\\b(\\w+)\\s+\\1\\b')\n",
    "g = p.search('Paris in the the spring')\n",
    "print(g.group())\n",
    "print(g.group(1))\n",
    "print(g.group(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<span class=\"Data\" id=\"BasicInfo1_lblAddress\">618 AIRBRAKE  AVE<br/>WILMERDING, PA 15148</span>']\n",
      "street:1_lblAddress\">618 AIRBRAKE  AVE\n",
      "city:WILMERDING\n",
      "Zip: 15148\n"
     ]
    }
   ],
   "source": [
    "### Tinkering with using regular expression splitting to parse out the address components for owners scraped\n",
    "### from county browser-based front end\n",
    "scrapedhtml = r'''<span class=\"Data\" id=\"BasicInfo1_lblAddress\">618 AIRBRAKE  AVE<br/>WILMERDING, PA 15148</span>'''\n",
    "l = re.split('<\\w>', scrapedhtml) \n",
    "print(l)\n",
    "\n",
    "splitlinelist = str(scrapedhtml).split('>')\n",
    "propaddrmap = {}\n",
    "if(len(splitlinelist) >= 2):\n",
    "    # match beg until any character not a <\n",
    "    exp = re.compile('\\d+[^<]*')\n",
    "    adr = exp.search(str(scrapedhtml))\n",
    "    # replace the html escape space with a single space\n",
    "    street = re.sub('&nbsp;', ' ', adr.group())\n",
    "    print(\"street:\" + street)\n",
    "    # take pairs of spaces down to one space\n",
    "    propaddrmap['street'] = re.sub('  ', ' ', street)\n",
    "    # on the city, state, zip line, grab until the comma before the state\n",
    "    exp = re.compile('[^,]*')\n",
    "    propaddrmap['city'] = exp.search(splitlinelist[2]).group()\n",
    "    print(\"city:\" + propaddrmap['city'])\n",
    "    # hard-code pa\n",
    "    propaddrmap['state']= 'PA'\n",
    "    # zip is just the last 5 chars    \n",
    "    propaddrmap['zip'] = splitlinelist[2][-12:-6]\n",
    "    print(\"Zip:\" + propaddrmap['zip'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: \n",
      "Important Text 1\n",
      "\n",
      "Found: \n",
      "Not Important Text\n",
      "\n",
      "Found: \n",
      "Important Text 2\n",
      "\n",
      "Found: \n",
      "Important Text 3\n",
      "\n",
      "Found: \n",
      "Non Important Text\n",
      "\n",
      "Found: \n",
      "Important Text 4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sylvia/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /home/sylvia/anaconda3/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "### Grabbed from SO on parsing out strangely structured HTML with BeatutifulSoup\n",
    "\n",
    "from bs4 import BeautifulSoup, NavigableString, Tag\n",
    "\n",
    "input = '''<br />\n",
    "Important Text 1\n",
    "<br />\n",
    "<br />\n",
    "Not Important Text\n",
    "<br />\n",
    "Important Text 2\n",
    "<br />\n",
    "Important Text 3\n",
    "<br />\n",
    "<br />\n",
    "Non Important Text\n",
    "<br />\n",
    "Important Text 4\n",
    "<br />'''\n",
    "\n",
    "soup = BeautifulSoup(input)\n",
    "\n",
    "for br in soup.findAll('br'):\n",
    "    next_s = br.nextSibling\n",
    "    if not (next_s and isinstance(next_s,NavigableString)):\n",
    "        continue\n",
    "    next2_s = next_s.nextSibling\n",
    "    if next2_s and isinstance(next2_s,Tag) and next2_s.name == 'br':\n",
    "        text = str(next_s).strip()\n",
    "        if text:\n",
    "            print(\"Found:\", next_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['618 AIRBRAKE  AVE', <br/>, 'WILMERDING,     PA 15148-23423']\n",
      "48\n",
      "PA\n",
      "15148\n",
      "<br/>\n",
      "done sleeping\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "scrapedhtml = r'''<span class=\"Data\" id=\"BasicInfo1_lblAddress\">618 AIRBRAKE  AVE<br/>WILMERDING,     PA 15148-23423</span>'''\n",
    "# scrapedhtml = r'''<span class=\"Data\" id=\"BasicInfo1_lblAddress\"><br/>WILMERDING, PA 15148</span>'''\n",
    "soup = BeautifulSoup(scrapedhtml, 'lxml')\n",
    "magiclist = soup.span.contents\n",
    "print(soup.span.contents)\n",
    "print(magiclist[2][-8:-6])\n",
    "exp=re.compile(',\\s*(\\w\\w)')\n",
    "m = re.search(exp,magiclist[2])\n",
    "print(m.group(1))\n",
    "exp=re.compile('\\d+')\n",
    "m = re.search(exp, magiclist[2])\n",
    "print(m.group())\n",
    "print(soup.span.br)\n",
    "time.sleep(3.232)\n",
    "print(\"done sleeping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# basic testing of error file writing\n",
    "import csv\n",
    "\n",
    "output_file = 'errorparcels.csv'\n",
    "CSV_FILE_ENCODING = 'utf-8'\n",
    "\n",
    "def logerror(parcelid):\n",
    "    fieldnames = None\n",
    "    with open(output_file, 'a', encoding=CSV_FILE_ENCODING) as outfile:\n",
    "        writer = csv.writer(outfile)\n",
    "        writer.writerow([parcelid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#calls to above logging method\n",
    "logerror('sdf2342')\n",
    "logerror('sdf2342')\n",
    "logerror('sdf2342')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0450L003500\n",
      "error\n"
     ]
    }
   ],
   "source": [
    "#extracting lot and block from parcel id\n",
    "# they look like this: 0545L00128000000\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "parid='0450L00350000000'\n",
    "trimmedparid = parid[0:11]\n",
    "print(trimmedparid)\n",
    "exp = re.compile(r'([1-9]+)(\\w)[0]*([1-9]+)')\n",
    "gl = re.search(exp, trimmedparid)\n",
    "if(gl):\n",
    "    lob = gl.group(1) + '-' + gl.group(2) + '-' + gl.group(3)\n",
    "    lob = gl.group(1) + '-' + gl.group(2) + '-' + gl.group(3)\n",
    "    print(lob)\n",
    "else:\n",
    "   print('error')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '_sre.SRE_Match'>\n",
      "('MCCONNELL', 'MARK', '&')\n",
      "Mark Mcconnell\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "owner_full_name = r'''MCCONNELL MARK & pat'''\n",
    "persondict = {}\n",
    "# soup = bs4.BeautifulSoup(property_html, 'lxml')\n",
    "# owner_full_name = soup.find('span', id=OWNER_NAME_SPAN_ID).text\n",
    "# Remove extra spaces from owner's name\n",
    "# persondict['note_namedump'] = re.sub(r'\\s+', ' ', owner_full_name.strip())\n",
    "# exp = re.compile(r'(\\w+|[&])\\s+(\\w+|[&])\\s+(\\w+|[&]).*')\n",
    "# exp = re.compile(r'(\\w+)\\s+(\\w+)\\s+(\\w+).*')\n",
    "# exp = re.compile(r'(.*)\\s+(\\w+)\\s+(\\w+).*')\n",
    "namegroups = re.search(r'([\\w\\']+)\\s+([\\w\\']+)\\s?(\\w+|&)?',owner_full_name)\n",
    "# namegroups = re.search(exp,owner_full_name)\n",
    "print(type(namegroups))\n",
    "print(namegroups.groups())\n",
    "if namegroups:    \n",
    "    if len(namegroups.groups())==3 and namegroups.group(3)!=None:\n",
    "        persondict['lname'] = namegroups.group(1)\n",
    "        if namegroups.group(3) != '&':\n",
    "            persondict['fname'] = str(namegroups.group(2)) + ' ' + str(namegroups.group(3))\n",
    "        else:\n",
    "            persondict['fname'] = str(namegroups.group(2))\n",
    "    else:\n",
    "        persondict['lname'] = namegroups.group(1)\n",
    "        persondict['fname'] = str(namegroups.group(2))\n",
    "    print(str(persondict['fname']).title() + ' ' + str(persondict['lname']).title())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
